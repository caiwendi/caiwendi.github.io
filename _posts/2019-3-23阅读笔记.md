---
layout:     post                    # 使用的布局（不需要改）
title:      DSSD Deconvolutional Single Shot Detector           # 标题 
subtitle:   论文阅读笔记 #副标题
date:       2019-03-23              # 时间
author:     Kiri                      # 作者
header-img: img/archives-bg-mayday.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - DSSD
---

# 阅读笔记

#### 论文相关信息：

**题目：**DSSD: Deconvolutional Single Shot Detector

**来源：**<https://arxiv.org/abs/1701.06659>（未在期刊或者会议发表）

**作者：**Cheng Yang Fu, Wei Liu, Ananth Ranga, Ambrish Tyagi, Alexander C. Berg

----

#### 摘要：

本文首先将ResNet-101与SSD结合，然后在SSD+ResNet-101的基础上增加反卷积层（deconvolutional layer）用于引入额外的大尺寸上下文信息用于目标检测闭关提高检测精度，尤其针对于小目标物体的检测。在VOC 2007测试集上取得了81.5%的平均测试精度，VOC 2012测试集上取得80.0%的平均测试精度，CoCo上则达到33.2%的平均测试精度，DSSD网络相较于R-FCN网络在各个数据集上表现要优秀。

----

#### 相关工作：

主流的目标检测算法包括SPPNet， Faster R-CNN， Faster R-CNN、R-FCN、YOLO等都是采用最顶层的卷积特征图学习在不同尺度上的目标检测，虽然十分有效，但是单层特征图上能够模拟的物体可能的尺寸和形状仍然是有限的。

通过在同一个卷积网络上的多个卷积特征图上进行预测以提高检测精度的方法主要分为以下几种：

- 结合来自卷积网络不同层的特征图，使用组合特征进行预测，具体的网络有ION、HyperNet。因为组合特征具有输入图像不同层次的特征，所以组合特征更适合定位和分类；但是由于组合特征不仅显著增加了模型的内存占用，而且降低了模型的速度。
- 利用同一个卷积网络中不同层的特征图预测不同尺寸的物体。由于在不同层的特征中的点具有不同的感受野，很自然的可知在感受野大的特征图中进行较大物体的预测，反之在感受野小的特征图中预测小物体。具体的网络有SSD、MS-CNN等。然而，为了取得较好的小目标检测效果，这些方法需要使用网络中浅层的具有较小感受野和密集特征图信息，由于浅层的特征具有较少的物体语义特征，因此可能对小物体的检测产生影响。
- 还有一种技术路线尝试使用包含上下文的信息用于预测（tries to include context information for prediction）

----

#### 模型：

![pic1](https://github.com/caiwendi/caiwendi.github.io/raw/master/img/DSSD-1.png)

**采用ResNet-101取代VGG：**

上图中的第一个网络结构为使用ResNet-101的SSD网络，其中在Conv5_x后添加了额外的几层卷积，并采用Conv3_x、Conv5_x以及额外添加的卷积层进行目标的位置偏差物体类别的预测。但是，基于ResNet-101的SSD网络在PASCAL VOC2007数据集上的检测平均精度为76.4，相较于原始SSD网络的精度77.5要低一些（输入图像均为$321 \times 321$）。

**预测模块：**

在原始SSD网络中，目标函数直接用与选定的特征图，并且在Conv3_4采用了L2Norm，由于梯度的幅度较大。

![pic1](https://github.com/caiwendi/caiwendi.github.io/raw/master/img/DSSD-2.png)

在改进后的网络中，文章对每一个预测层添加了一个残差块。并且通过实验，发现具有改进后的预测模块基于ResNet-101的SSD网络的预测精度比原始SSD（输入图像均为$321 \times 321$）网络要明显有所提升。

**反卷积模块：**

![pic1](https://github.com/caiwendi/caiwendi.github.io/raw/master/img/DSSD-3.png)

为了整合浅层特征图和反卷积层的信息，文章引入了反卷积模块，如上图所示，首先在每一个卷积层之后加入一个BatchNorm层，接下来使用可学习的反卷积层代替双线性上采样，最后将高层特征与底层特征融合：其中实验数据结果表明采用element-wise相乘的方法检测精度比相加方法的精度要高（element-wise sum and element-wise product.
The experimental results show that the element-wise product provides the best accuracy）。

----

#### 网络训练：

本文跟循SSD的训练策略，首先，将一系列默认框与目标的GT进行匹配，对于每一个GT与IOU大于0.5的默认框进行匹配，在未匹配的默认框中失选择某部分框作为负例，接下来最小化候选框损失和置信度损失。

在SSD模型中采用长宽比为2和3的默认框，在实验中被证明十分有效。为了得到PASCAL VOC 2007和2012 trainval图片里各个物体对应的真实位置框的长宽比例，本文用K-means对这些真实框内区域面积的平方根作为特征做了一个聚类分析，文中从两个类开始，然后逐步增加类数目直到收敛损失最低。

因为SSD训练时使用的训练图片会重新调整比例变成方形的尺寸，但是在大多数的训练图片都是比较宽的图片，所以相应的真实框的宽度会变小一点。通过这种聚类实验最后确定了预测使用的default box的长宽比例为1、1.6、2和3，作为每一个特征图的default
box所使用的长宽比例。