---
layout:     post                    # 使用的布局（不需要改）
title:      Multi-task Convolutional Neural Network for Patient Detection and Skin Segmentation in Continuous Non-contact Vital Sign Monitoring           # 标题 
subtitle:   论文阅读笔记 #副标题
date:       2019-04-12              # 时间
author:     Kiri                      # 作者
header-img: img/archives-bg-mayday.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - Detection
---

#阅读笔记 

## 论文相关信息

**题目：**Multi-task Convolutional Neural Network for Patient Detection and Skin Segmentation in Continuous Non-contact Vital Sign Monitoring

**作者：**Sitthichok Chaichulee, Mauricio Villarroel, Joao Jorge, Carlos Arteta, Gabrielle Green, Kenny McCormick, Andrew Zisserman, and Lionel Tarassenko

**来源：**[2017 12th IEEE International Conference on Automatic Face & Gesture Recognition]([https://ora.ox.ac.uk/objects/uuid:9055fb50-467c-40c6-b789-b4806cd96452/download_file?file_format=pdf&safe_filename=Zisserman%2Bet%2Bal%252C%2BMulti-task%2Bconvolutional%2Bneural%2Bnetwork%2Bfor%2Bpatient%2Bdetection%2Band%2Bskin%2Bsegmentation%2Bin%2Bcontinuous%2Bnon-con.pdf&type_of_work=Conference+item](https://ora.ox.ac.uk/objects/uuid:9055fb50-467c-40c6-b789-b4806cd96452/download_file?file_format=pdf&safe_filename=Zisserman%2Bet%2Bal%2C%2BMulti-task%2Bconvolutional%2Bneural%2Bnetwork%2Bfor%2Bpatient%2Bdetection%2Band%2Bskin%2Bsegmentation%2Bin%2Bcontinuous%2Bnon-con.pdf&type_of_work=Conference+item))

---

## 摘要

病患检测和皮肤分割是非接触式生命体监测的重要步骤，因为皮肤区域包含估计生命特征所需的动脉信息，如心率，呼吸频率和外围血氧饱和浓度（SpO~2~），以往基于面部检测或者基于颜色的图像分割的方法在医院的环境中可靠性差。因此本文提出了一种多任务卷积神经网络，用于检测是否存在患者，并对患者皮肤区域进行分割，该模型共享核心网络，并具有两个分支：分割分支采用全卷积网络，分类分支采用全局平均池化。使用来自英国牛津John Radcliffe医院的新生儿重症监护室（NICU）进行临床研究的图片训练整个网络。该模型可以预测准确的结果，并对不同肤色，姿势变化，照明变化以及临床工作人员常规交互的变换具有鲁棒性。

---

## 数据集

- 临床研究

- 半自动皮肤区域标注

  ![pic1](https://github.com/caiwendi/caiwendi.github.io/raw/master/img/Patient_detection-1.png)

  为了减少人工标注的工作量，首先需要对视频的 第一帧进行标注，并将标签传送至下一帧，然后gaozhilia 基于Gulshan等人提出的GSC算法实现皮肤区域的标注。具体的流程如上图所示。

- 注释协议

  - 采用三个人工标注，保证高质量的GroundTruth
  - 考虑光照变换的影响，对每一个视频流每6分钟进行一次采样，获取2269张图像
  - 在原始的分别率上进行图像的标注
  - 对于每一个session，需要提供第一张图像在皮肤区域和非皮肤区域的笔触，然后进行标注的计算，之后的图像仅需标注器自动生成分割seed和皮肤标注，如果给出的注释符合期望，则进行下一张图的注释，如果不是，则修改seed用于修改注释
  - 如果图像中婴儿不在，或包含医护人员或婴儿父母，以及场景太暗无法进行分割或婴儿正在治疗等情况，则跳过该图像

- 数据集结构
  - 正例图像：包含婴儿的图像，并有像素集的分割标注
  - 负例图像：婴儿不在的图像

---

##  方法

- 病患检测与皮肤分割网络

  ![pic2](https://github.com/caiwendi/caiwendi.github.io/raw/master/img/Patient_detection-2.png)

  本文将问题公式化为在一个卷积神经网络中进行两个分支任务，一个用于分类，另一个用于图像分割。

  **共享核心网络：** 采用VGG-16网络

  **病患检测分支：**在``Pool 5``池化层后增加一个具有两输出的$1\times 1$的卷积层，用于减少特征图维度并能预测两类，然后经过一个全局平均池化层，产生的输出经过softmax层计算得到两类的概率估计。

  **皮肤分割分支：**首先在``Pool 3``和``Pool 4``两个池化层的顶部添加一个二维输出的$1\times1$的卷积层，以便在更高的分辨率上产生额外的两种输出；接下来，``Conv 8``输出的预测图通过卷积转置层进行空间上采样（上采样因数为2），与``Pool 4``池化层经过$1\times1$的卷积层预测输出图进行融合；然后相同的将输出特征图进行上采yu 样再与``Pool 3``池化层经过$1\times1$的卷积层预测输出图进行融合，最后经过一个上采样因子为8的上采样层输出与原始图像相同空间大小的预测图，经过一个softmsx层获得分割结果

- 网络训练

  **数据预处理： **所有的图像和GT都按比例放缩，然后在图像的上下部分添加black space，使图像大小为$512 \times512$

  **数据增强：**旋转、翻转、亮度调节

  **损失函数：**病患检测采用多项逻辑损失；皮肤分割采用多项逻辑损失在整个空间像素输出上求和，并相对于GT像素的数值进行归一化；整个网络的损失为两个分支的损失按照权值进行相加

  **模型初始化：**在共享核心网络中的卷积层和ReLU层之间添加了Batchnorm层；并且采用原始的VGG-16网络权值对核心网络进行初始化，新加的权值层，除了转置卷积层采用具有0偏差的Xavier算法进行初始化，转置卷积层采用没有偏差的双线性滤波器进行初始化

  **训练流程：**优化算法采用的SGD。第一阶段，训练皮肤分割任务分支，学习率为1e-2并且每两个epoch下降10倍直到模型收敛，动量因子为0.9，每个batch中图片为20张；第二阶段采用整个数据集训练两个分支，初始学习率为1e-4并且每两个epoch下降10倍直到模型收敛，动量因子为0.9，每个batch中图片为20张







<html>

<head>
<title>MathJax TeX Test Page</title>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
</script>
</head>
<body>