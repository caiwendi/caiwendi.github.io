<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Deep Convolutional Nets for Semantic Image Segmentation with Deep Gaussian CRFs               # 标题</title><link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --code-block-bg-color: inherit; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { background: rgb(181, 214, 252); text-shadow: none; }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; word-wrap: break-word; position: relative; padding-bottom: 70px; white-space: pre-wrap; overflow-x: visible; contain: content; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
.typora-export #write { margin: 0px auto; }
#write > p:first-child, #write > ul:first-child, #write > ol:first-child, #write > pre:first-child, #write > blockquote:first-child, #write > div:first-child, #write > table:first-child { margin-top: 30px; }
#write li > table:first-child { margin-top: -20px; }
img { max-width: 100%; vertical-align: middle; }
input, button, select, textarea { color: inherit; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; font-size: inherit; line-height: inherit; font-family: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
::before, ::after, * { box-sizing: border-box; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write div, #write pre { width: inherit; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6 { position: relative; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
p { -webkit-margin-before: 1rem; -webkit-margin-after: 1rem; -webkit-margin-start: 0px; -webkit-margin-end: 0px; }
.typora-export p { white-space: normal; }
.mathjax-block { margin-top: 0px; margin-bottom: 0px; -webkit-margin-before: 0rem; -webkit-margin-after: 0rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: bold; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; margin: 4px 0px 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
pre { white-space: pre-wrap; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: var(--code-block-bg-color); position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
.md-fences .CodeMirror.CodeMirror-wrap { top: -1.6em; margin-bottom: -1.6em; }
.md-fences.mock-cm { white-space: pre-wrap; }
.show-fences-line-number .md-fences { padding-left: 0px; }
.show-fences-line-number .md-fences.mock-cm { padding-left: 40px; }
.footnotes { opacity: 0.8; font-size: 0.9rem; padding-top: 1em; padding-bottom: 1em; }
.footnotes + .footnotes { margin-top: -1em; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: transparent; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: normal; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li p, li .mathjax-block { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; }
@media print {
  html, body { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  h1, h2, h3, h4, h5, h6 { break-after: avoid-page; orphans: 2; }
  p { orphans: 4; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; padding-bottom: 0px; break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0mm; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 2.86rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.mathjax-block { white-space: pre; overflow: hidden; width: 100%; }
p + .mathjax-block { margin-top: -1.143rem; }
.mathjax-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: none; box-shadow: none; }
.task-list { list-style-type: none; }
.task-list-item { position: relative; padding-left: 1em; }
.task-list-item input { position: absolute; top: 0px; left: 0px; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc::after, .md-toc-content::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: bold; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
.md-tag { opacity: 0.5; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: monospace; }
code { text-align: left; }
h1 .md-tag, h2 .md-tag, h3 .md-tag, h4 .md-tag, h5 .md-tag, h6 .md-tag { font-weight: initial; opacity: 0.35; }
a.md-print-anchor { border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: none !important; background: transparent !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.mathjax-block .MathJax_SVG_Display { text-align: center; margin: 1em 0em; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: monospace; }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: normal; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; }


:root { --side-bar-bg-color: #fafafa; --control-text-color: #777; }
@font-face { font-family: "Open Sans"; font-style: normal; font-weight: normal; src: local("Open Sans Regular"), url("./github/400.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: normal; src: local("Open Sans Italic"), url("./github/400i.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: normal; font-weight: bold; src: local("Open Sans Bold"), url("./github/700.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: bold; src: local("Open Sans Bold Italic"), url("./github/700i.woff") format("woff"); }
html { font-size: 16px; }
body { font-family: "Open Sans", "Clear Sans", "Helvetica Neue", Helvetica, Arial, sans-serif; color: rgb(51, 51, 51); line-height: 1.6; }
#write { max-width: 860px; margin: 0px auto; padding: 20px 30px 100px; }
#write > ul:first-child, #write > ol:first-child { margin-top: 30px; }
body > :first-child { margin-top: 0px !important; }
body > :last-child { margin-bottom: 0px !important; }
a { color: rgb(65, 131, 196); }
h1, h2, h3, h4, h5, h6 { position: relative; margin-top: 1rem; margin-bottom: 1rem; font-weight: bold; line-height: 1.4; cursor: text; }
h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor { text-decoration: none; }
h1 tt, h1 code { font-size: inherit; }
h2 tt, h2 code { font-size: inherit; }
h3 tt, h3 code { font-size: inherit; }
h4 tt, h4 code { font-size: inherit; }
h5 tt, h5 code { font-size: inherit; }
h6 tt, h6 code { font-size: inherit; }
h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid rgb(238, 238, 238); }
h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid rgb(238, 238, 238); }
h3 { font-size: 1.5em; line-height: 1.43; }
h4 { font-size: 1.25em; }
h5 { font-size: 1em; }
h6 { font-size: 1em; color: rgb(119, 119, 119); }
p, blockquote, ul, ol, dl, table { margin: 0.8em 0px; }
li > ol, li > ul { margin: 0px; }
hr { height: 4px; padding: 0px; margin: 16px 0px; background-color: rgb(231, 231, 231); border-width: 0px 0px 1px; border-style: none none solid; border-top-color: initial; border-right-color: initial; border-left-color: initial; border-image: initial; overflow: hidden; box-sizing: content-box; border-bottom-color: rgb(221, 221, 221); }
body > h2:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child + h2 { margin-top: 0px; padding-top: 0px; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child { margin-top: 0px; padding-top: 0px; }
a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 { margin-top: 0px; padding-top: 0px; }
h1 p, h2 p, h3 p, h4 p, h5 p, h6 p { margin-top: 0px; }
li p.first { display: inline-block; }
ul, ol { padding-left: 30px; }
ul:first-child, ol:first-child { margin-top: 0px; }
ul:last-child, ol:last-child { margin-bottom: 0px; }
blockquote { border-left: 4px solid rgb(221, 221, 221); padding: 0px 15px; color: rgb(119, 119, 119); }
blockquote blockquote { padding-right: 0px; }
table { padding: 0px; word-break: initial; }
table tr { border-top: 1px solid rgb(204, 204, 204); margin: 0px; padding: 0px; }
table tr:nth-child(2n) { background-color: rgb(248, 248, 248); }
table tr th { font-weight: bold; border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr td { border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr th:first-child, table tr td:first-child { margin-top: 0px; }
table tr th:last-child, table tr td:last-child { margin-bottom: 0px; }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); }
.md-fences, code, tt { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; }
.md-fences { margin-bottom: 15px; margin-top: 15px; padding: 8px 1em 6px; }
.task-list { padding-left: 0px; }
.task-list-item { padding-left: 32px; }
.task-list-item input { top: 3px; left: 8px; }
@media screen and (min-width: 914px) {
}
@media print {
  html { font-size: 13px; }
  table, pre { break-inside: avoid; }
  pre { word-wrap: break-word; }
}
.md-fences { background-color: rgb(248, 248, 248); }
#write pre.md-meta-block { padding: 1rem; font-size: 85%; line-height: 1.45; background-color: rgb(247, 247, 247); border: 0px; border-radius: 3px; color: rgb(119, 119, 119); margin-top: 0px !important; }
.mathjax-block > .code-tooltip { bottom: 0.375rem; }
#write > h3.md-focus::before { left: -1.5625rem; top: 0.375rem; }
#write > h4.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h5.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h6.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
.md-image > .md-meta { border: 1px solid rgb(221, 221, 221); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; color: inherit; }
.md-tag { color: inherit; }
.md-toc { margin-top: 20px; padding-bottom: 20px; }
.sidebar-tabs { border-bottom: none; }
#typora-quick-open { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); }
#typora-quick-open-item { background-color: rgb(250, 250, 250); border-color: rgb(254, 254, 254) rgb(229, 229, 229) rgb(229, 229, 229) rgb(238, 238, 238); border-style: solid; border-width: 1px; }
#md-notification::before { top: 10px; }
.on-focus-mode blockquote { border-left-color: rgba(85, 85, 85, 0.12); }
header, .context-menu, .megamenu-content, footer { font-family: "Segoe UI", Arial, sans-serif; }
.file-node-content:hover .file-node-icon, .file-node-content:hover .file-node-open-state { visibility: visible; }
.mac-seamless-mode #typora-sidebar { background-color: var(--side-bar-bg-color); }
.md-lang { color: rgb(180, 101, 77); }






</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-node show-fences-line-number'><h2><a name='header-n888' class='md-header-anchor '></a>1、会议论文汇报PPT</h2><p><img src='https://i.imgur.com/6uH8w0w.png' alt='' />
<img src='https://i.imgur.com/C8me9BC.png' alt='' />
<img src='https://i.imgur.com/QwqHDgS.png' alt='' />
<img src='https://i.imgur.com/IF0SwJB.png' alt='' />
<img src='https://i.imgur.com/udxmhiP.png' alt='' /></p><p><img src='https://i.imgur.com/FaxK2y8.png' alt='' />
<img src='https://i.imgur.com/XyQ8xif.png' alt='' />
<img src='https://i.imgur.com/avRSuT0.png' alt='' />
<img src='https://i.imgur.com/9jS4zHB.png' alt='' />
<img src='https://i.imgur.com/6FcoDDB.png' alt='' /></p><p><img src='https://i.imgur.com/ain5alI.png' alt='' />
<img src='https://i.imgur.com/A2GwDd5.png' alt='' />
<img src='https://i.imgur.com/jr60kCH.png' alt='' />
<img src='https://i.imgur.com/Ss1ZAfH.png' alt='' />
<img src='https://i.imgur.com/loU2aSh.png' alt='' /></p><p><img src='https://i.imgur.com/ZiKLFsW.png' alt='' />
<img src='https://i.imgur.com/zv0EudO.png' alt='' />
<img src='https://i.imgur.com/fVa3S3F.png' alt='' />
<img src='https://i.imgur.com/7K53LxF.png' alt='' />
<img src='https://i.imgur.com/2wuLmdN.png' alt='' /></p><hr /><h2><a name='header-n914' class='md-header-anchor '></a>2、中文演讲稿</h2><p>各位教授，大家好</p><ol start='' ><li>我汇报的题目是<strong>Deep Convolutional Nets for Semantic Image Segmentation with Deep Gaussian CRFs</strong>,</li><li>我将从以下四个方面介绍我的研究成果，第一方面介绍我们需要解决难题和我们用到的基本方法，第二方面和第三方面分别介绍解决该问题的前期卷积神经网络处理过程和后期高斯条件随机场处理过程，最后对我们研究的结果做了基本总结。  <br/></li><li>图像语义分割是针对图片的每一个像素进行分类，该技术是场景分类，目标追踪等领域的基石，目前语义分割的方法是通过卷积神经网络进行像素分类，该方法的缺点是由于卷积神经网络的空间不变性导致的定位精度不高，难以得到理想的结果。为了克服这一缺点，达到卷积神经网络的分类准确性和定位精度的平衡，我们采用以下三种方法：多尺度分割，降低卷积神经网络的感受野，条件随机场做后期处理。</li><li>整个语义分割过程分为两个部分：第一个部分是采用卷积神经网络作为前期处理来处理分类问题，我们通过降低感受野方法来缩短计算时间和多尺度预测获得更多低维特征提高边界定位精度。</li><li>第二个部分是采用高斯条件随机场作为后期处理来解决定位问题，我们通过恢复丢失的边缘信息得到准确的语义分割结果。</li><li>接下来这个图展示我们整个研究过程的思路，红色虚线左边是作为语义分割前期处理的卷积神经网络，红色虚线右边是作为语义分割后期处理的高斯条件随机场。用来训练整个网络的数据库是The VOC PASCAL 2012</li><li>接下来介绍卷积神经网络作为语义分割前期处理的具体内容：</li><li>降低感受野的目的为了减少运行时间，如红色的方框中，需要对每一个第一个全连接层进行子采样。</li><li>为了获得更多低维特征采用多尺度来方法提高边界定位精度, 前面四个最大池化层中的每一个的输出和输入图像被附加到两层多层感知器（MLP）。</li><li>接下来介绍高斯条件随机场作为语义分割后期处理的具体内容</li><li>整个语义分割的后期处理过程采用高斯条件随机场，我们将条件随机场的能量函数定义为下面形式，要保证全局最小的条件是<img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvkl473yg203000i0d9.gif' alt='' />, 为了达到此条件让整个模型收敛，可以通过链式求导规则求解出A和B的梯度。</li><li>下面我们采用了另一种方法可以让整个模型收敛的更快, 通过Potts-type pairwise模型将二元能量形式转化为每个像素匹配一个标签，再将收敛条件的等式转化为矩阵形式，</li><li>然后通过链式求导法和一系列推导得出<img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvlkb28vg200d00h04b.gif' alt='' />的梯度。</li><li>以上得到权重的梯度后，最后用Softmax进行分类，对每个像素和标签的匹配给出概率值，这些概率值由交叉熵进行惩罚处理，最后随着训练次数的增加，交叉熵的损失值越小，模型的预测会越精准。</li><li>下面对实验的部分进行介绍，数据集采用PASCAL VOC 2012,分为训练集，验证集和测试集，一共有20个物体类和1个背景，分割的标准是交除并，在训练过程中，我们采用在ImageNet上预训练好的DCNN，交叉熵损失值的下降方式采用共轭梯度下降，经过不断试验最后选定的Mini-batch = 20, Momentum = 0.9, Weight decay =<img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvly8flpg201h00g088.gif' alt='' /> , Learning rate = 0.001并且每迭代2000次学习率降低10倍。</li><li>下面是我们提出方法的具体实验数据，表一是增强训练数据集训练的模型在验证集下的准确率，我们看到Basenet的准确率是62.25%，每一个红色矩形部分中的数据比上一组数据高大约1%左右，最好的结果采用多尺度，二次优化和条件随机场达到76.40%。表二和表一的区别在于表二扩大了数据集，达到最高的准确率78.3%。由此得出，我们采用方法的有效性。</li><li>下面是我们将原始图片分割后的效果，第一列是原始图片，第二列是手工标注的图片，第三列是二次优化分割的效果，第四列是多尺度和二次优化分割的效果，最后一列是将多尺度，二次优化和条件随机场做结合分割效果图，可以观察到结合这三种方法捕捉到了更多细节和获得了更好的分割效果。</li><li>最后对我们的研究成果进行总结</li><li>我们的结论主要分为三个方面: 通过控制感受野的大小，能在不损失性能的情况下减少运算的时间；多尺度分割方法能够提高边缘定位精度；最后高斯条件随机场能够进一步捕捉细腻的边缘信息获得更好的分割效果。</li><li>我的汇报结束，谢谢大家的聆听。</li></ol><hr /><h2><a name='header-n979' class='md-header-anchor '></a>3、英文演讲稿</h2><p>Dear professors, good morning/afternoon:</p><ol start='' ><li>Thank you for giving me an opportunity to speak about what I have done at this special occasion, what I am going to talk about today is my topic ,Deep Convolutional Nets for Semantic Image Segmentation with Deep Gaussian CRFs.</li><li>I will introduce our research results by the following four parts. The  introduction is about what kind of problem we need to solve  and how we deal with it , the second part is about convolutional neural network as pre-processing of solution to the problem, the third part is about Gaussian condition random fields as post-processing, Finally, we summarize the results of our study.</li><li>Image semantic segmentation is to classify each pixel of the picture, which is the cornerstone of scene classification and target tracking. The current main semantic segmentation method is to classify pixels by convolutional neural network. The disadvantage of this method is the spatial invariance of the convolutional neural network,which can cause limited positioning accuracy, what is more, it is difficult to get the  desired results. In order to overcome this shortcoming, to achieve balance between the classification and the positioning accuracy of of the convolutional neural network, we use the following three methods: multi-scale segmentation, reduce the receptive of  convolutional neural network and conditional random field as post-processing.</li><li>The whole semantic segmentation process is divided into two parts: the first part is to use convolutional  neural network as a pre-processing to deal with the classification problem, so we can decrease the calculation time by reducing the receptive field and multi-scale prediction can  obtain more low-dimensional features to improve the border position accuracy.</li><li>The second part is to use the Gaussian conditional random field as a post-processing to solve the localization problem, so  we get the exact semantic segmentation result by recovering the missing edge information.</li><li>Next, this figure shows the main idea of our whole research process. The left side of the red dotted line is a convolutional neural network as pre-processing of semantic segmentation.  The right side of the red dotted line is the Gaussian conditional random field as post-processing of semantic segmentation. The database, The VOC PASCAL 2012, is used to train the entire network.</li><li>Next, I will explain the details of semantic segmentation pre-processing:</li><li>In order to decrease the calculation time, we need to reduce the receptive field.  Look at the red rectangle, spatially subsampling (by simply extracting) the first FC layer to a 4×4 (or 3×3) spatial size.</li><li>In order to obtain more low-dimensional features, the multi-scale method is used to improve the boundary position accuracy. The output and input image of each of the top four largest pooling layers are added to the two-layer multi-layer perceptron (MLP).</li><li>Then, we introduce Gaussian conditional random field as the  post-processing  of semantic segmentation.</li><li>In the post-processing of the whole semantic segmentation, we use the Gaussian conditional random field. We define the energy function of the conditional random field as the following form. To ensure that the global minimum condition is <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvkl473yg203000i0d9.gif' alt='' /> and the whole model convergence,  the gradient of A and B can be solved in terms of chaining rule.</li><li>Here we use another method to make the whole model converge faster. A Potts-type pairwise model is
proposed to describe by the  following equation , the pairwise energy term is denoted for <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvts3zpeg200e00c048.gif' alt='' /> pixel taking the <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvu9oq6lg200900g03l.gif' alt='' />label, and  <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvujhwytg200g00e04m.gif' alt='' /> pixel taking the <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvutl8pag200b00j03y.gif' alt='' /> label.To derive the inference and gradient equations, the inference equation <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvkl473yg203000i0d9.gif' alt='' /> is rewritten as Matrix form.</li><li>And then through the chain derivation rule and a series of inferences, we can get  <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvlkb28vg200d00h04b.gif' alt='' />  gradient.</li><li>After the gradient of every weight is obtained, the probability is given by Softmax, and the probability value is given for each pixel and label. These probability values are penalized by cross-entropy. Finally, with the increase of training times, the smaller the loss of cross entropy is, the more accurate the model will be.</li><li>The experimental part will be explained, the dataset is PASCAL VOC 2012, divided into training set, validation set and test set, including 20 objects classes and a background, image segmentation performance is measured in the terms of intersection-over-union(IOU) averaged across the 21 classes. During training processes, We used the pre-trained DCNN on IMAGENET, the cross-entropy loss function is conjugate gradient descent, and the final parameters as follow:  Mini-batch = 20, Momentum = 0.9, Weight decay = <img src='http://ww1.sinaimg.cn/large/b4c0024fgy1fkjvly8flpg201h00g088.gif' alt='' />, Learning rate = 0.001 and multiply 10 times per iteration of 2000 learning rates.</li><li>The following is the specific experimental data of our proposed method. Table 1 shows  the accuracy values under the validation set after model was trained in augmented training set, we see Basenet accuracy is 62.25%, each the data in red rectangle is approximately 1% higher than the previous one, the best results is up to  76.40% using multi-scale, secondary optimization and conditional random field. The difference between Table 2 and Table 1 is that Table 2 have the larger data set to achieve the highest accuracy rate of 78.3%.So it proves our method effective.</li><li>we can see visual results on the VOC PASCAL 2012 test set. The first column is the raw image, the second column shows the ground-truth of image segmentation, the third column shows the predicted segmentation of quadratic optimization model , the fourth column is  the predicted segmentation with combination of multi-scale and quadratic optimization, the last column shows outputs after the multi-scale, quadratic optimization and conditional random field are applied to our model, you can observe the combination of these three methods to capture more details and get a better segmentation results.</li><li>Finally, we summarize our research results.</li><li>Our conclusions are divided into three aspects. First, controlling the receptive field size can decrease computation time and memory capacity without sacrificing performance; Second,  a multi-scale prediction method can increase the boundary localization accuracy; Finally, Gaussian conditional random fields can obtain object boundaries at a level of detail and produce accurate predictions and detailed segmentation maps;</li><li>That&#39;s all, thank you for listening.</li></ol><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p></div>
</body>
</html>